<!--
 * @Author: Charlie
 * @Date: 2020-05-30 14:34:14
 * @LastEditTime: 2020-06-05 18:07:34
 * @LastEditors: Peng Tianhao
 * @Description: 学习笔记
 * @FilePath: \Dive-into-DL-PyTorch\README.md
 * @No Bugs Here!👇
--> 
# 进度

**#2020年5月30日14点34分**

看完了 docs/3.1

**#2020年5月30日16点13分**

看完了 docs/3.3

**#2020年5月30日17点01分**

看完了 docs/3.5

**#2020年5月30日22点27分**

看完了 docs/3.7

**#2020年5月31日11点48分**

看完了 docs/3.13

**#2020年6月1日17点40分**

看完了 docs/3.16

**#2020年6月1日21点53分**

看完了 docs/4.2

**#2020年6月2日15点07分**

看完了 docs/4.6

**#2020年6月2日17点46分**

看完了 docs/5.5

**#2020年6月4日18点04分**

看完了 docs/5.12

**#2020年6月5日18点07分**

看完了 docs/6.6


# 笔记

### 1. dropout

通常的建议是把靠近输入层的丢弃概率设得小一点。在这个实验中，我们把第一个隐藏层的丢弃概率设为0.2，把第二个隐藏层的丢弃概率设为0.5。

![](My_img/2020-06-02-17-44-39.png)

### 2. 构建模型结构

![](My_img/2020-06-01-21-09-54.png)

### 3. Dict & OrderDict

![](My_img/2020-06-01-21-22-42.png)

![](My_img/2020-06-01-21-22-56.png)

OrderDict可以用来构建module:

![](My_img/2020-06-01-21-25-11.png)

![](My_img/2020-06-01-21-36-09.png)

### 4. 搭建自定义的网络模块

见docs/4.4

### 5. 保存 & 加载模型

![](My_img/2020-06-02-15-01-40.png)

![](My_img/2020-06-02-15-03-14.png)

### 6. 查看CUDA相关参数的命令

![](My_img/2020-06-02-15-05-27.png)

### 7. pooling layer 的作用

![](My_img/2020-06-02-16-48-46.png)

![](My_img/2020-06-02-17-20-09.png)

### 8. 困惑度-评价模型的指标

![](My_img/2020-06-05-17-22-27.png)

### 9. RNN底层代码/原理实现

见docs/ 6.4 

### 10. RNN loss计算图

![](My_img/2020-06-05-17-55-27.png)


# 疑问

1. docs/ 6.2 

![](My_img/2020-06-05-16-23-22.png)

